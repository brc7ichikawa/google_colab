{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brc7ichikawa/google_colab/blob/master/keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "xe9NfHTa2XjH",
        "colab_type": "code",
        "outputId": "07e04c8e-e627-4e18-a648-e56c3473c66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np \n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout\n",
        "from keras.optimizers import SGD, RMSprop, Adam\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from make_tensorboard import make_tensorboard\n",
        "import sys\n",
        "\n",
        "np.random.seed(1671)\n",
        "NB_EPOCH = 20\n",
        "BATCH_SIZE = 128\n",
        "VARBOSE = 1\n",
        "NB_CLASSES = 10 \n",
        "OPTIMIZER = Adam()\n",
        "N_HIDDEN = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "DROPOUT = 0.3\n",
        "MODEL_DIR = './tmp'\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
        "RESHAPED = 784 \n",
        "\n",
        "X_train = X_train.reshape(60000,RESHAPED)\n",
        "X_test = X_test.reshape(10000, RESHAPED)\n",
        "\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "Y_train = np_utils.to_categorical(Y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(Y_test, NB_CLASSES)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(N_HIDDEN, input_shape = (RESHAPED,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(N_HIDDEN))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(DROPOUT))\n",
        "model.add(Dense(NB_CLASS))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss= 'categorical_crossentropy', optimizer=OPTIMIZER, metrics=['accuracy'])\n",
        "\n",
        "#callbacks = [make_tensorboard(set_dir_name = 'keras_MINST_V3')]\n",
        "callbacks = [ModelCheckpoint(save_best_only = True, filepath = os.path.join(MODEL_DIR, \"model-{epoch:02d}.h5\"))]\n",
        "model.fit(X_train,\n",
        "         Y_train,\n",
        "         batch_size = BATCH_SIZE, epochs = NB_EPOCH,\n",
        "         callbacks = callbacks,\n",
        "         verbose = VARBOSE,\n",
        "         validation_split=VALIDATION_SPLIT)\n",
        "score = model.evaluate(X_test, Y_test, verbose=VARBOSE)\n",
        "print('TEST SCORE:', score[0])\n",
        "print('TEST accuracy:', score[1])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (60000, 28, 28)\n",
            "X_train_reshape: (60000, 784)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tdz_AaGSRPV5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!ls -alh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "90gU7Vz6A-op",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HAMelv2PUIGz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten, Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras.datasets import mnist\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "def lenet(input_shape, num_classes):\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(20, kernel_size = 5, padding = 'same',\n",
        "                   input_shape = input_shape, activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  model.add(Conv2D(50, kernel_size = 5, padding = 'same', activation = 'relu'))\n",
        "  model.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(500, activation = 'relu'))\n",
        "  model.add(Dense(num_classes))\n",
        "  model.add(Activation('softmax'))\n",
        "  return model\n",
        "  \n",
        "class MNISTDataSet():\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.image_shape = (28,28,1)\n",
        "    self.num_classes = 10\n",
        "    \n",
        "  def get_batch(self):\n",
        "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "    x_train, x_test = [self.processes(d) for d in[x_train, x_test]]\n",
        "    y_train, y_test = [self.processes(d, label_data = True) for d in [y_train, y_test]]\n",
        "    return x_train, y_train, x_test, y_test\n",
        "  \n",
        "  def processes(self, data, label_data = False):\n",
        "    if label_data:\n",
        "      data = keras.utils.to_categorical(data, self.num_classes)\n",
        "      #print(data.shape)\n",
        "    else:\n",
        "      data = data.astype('float32')\n",
        "      data /= 255\n",
        "      \n",
        "      shape = (data.shape[0],) + self.image_shape\n",
        "      #print(shape)\n",
        "      \n",
        "      data = data.reshape(shape)\n",
        "      #print(data[0][20])\n",
        "      #sys.exit()\n",
        "    return data\n",
        "\n",
        "class Trainer():\n",
        "  def __init__(self, model, loss, optimizer):\n",
        "    self._target = model\n",
        "    self._target.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "    self.verbose = 1\n",
        "    self.log_dir = os.path.join(os.path.dirname(\"make_tensorboard.py\"), 'logdir')\n",
        "    \n",
        "  def train(self, x_train, y_train, batch_size, epochs, validation_split):\n",
        "    if os.path.exists(self.log_dir):\n",
        "      import shutil\n",
        "      shutil.rmtree(self.log_dir)\n",
        "    os.mkdir(self.log_dir)\n",
        "    \n",
        "    self._target.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, \n",
        "                    validation_split = validation_split, callbacks=[TensorBoard(log_dir = self.log_dir)],\n",
        "                    verbose = self.verbose)\n",
        "    \n",
        "mnist_ = MNISTDataSet()\n",
        "x_train, y_train, x_test, y_test = mnist_.get_batch()\n",
        "model = lenet(mnist_.image_shape, mnist_.num_classes)\n",
        "trainer = Trainer(model, loss = \"categorical_crossentropy\", optimizer=Adam())\n",
        "trainer.train(x_train, y_train, batch_size = 128, epochs = 12, validation_split = 0.2)\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose = 0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mSmhiux7BHEf",
        "colab_type": "code",
        "outputId": "96bc3e2d-6867-4a07-b0d9-770efb472cce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "cell_type": "code",
      "source": [
        "!tensorboard --logdir=./logdir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorBoard 1.12.2 at http://fcb6bd4f03c0:6006 (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}